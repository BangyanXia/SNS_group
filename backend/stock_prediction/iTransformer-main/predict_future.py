import os
import torch
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler
from model.iTransformer import Model  # ç¡®ä¿ iTransformer ä»£ç è·¯å¾„æ­£ç¡®

# **ğŸš¨ å¼ºåˆ¶ä½¿ç”¨ CPU è¿è¡Œ**
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# **ğŸ”¹ é…ç½®æ–‡ä»¶è·¯å¾„**
checkpoint_path = "./checkpoints/stock_iTransformer_custom_M_ft365_sl48_ll7_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0/checkpoint.pth"  # ä½ çš„è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶
data_path = "./cleaned_stock_fed_rate.csv"  # ä½ çš„æ•°æ®é›†æ–‡ä»¶
pred_len = 7  # **é¢„æµ‹æœªæ¥ 7 å¤©**

# **ğŸ”¹ å¼ºåˆ¶ä½¿ç”¨ CPU**
device = torch.device("cpu")
print(f"âœ… è®¾å¤‡: {device}")

# **ğŸ”¹ åŠ è½½æ•°æ®**
df = pd.read_csv(data_path)
df['date'] = pd.to_datetime(df['date'])

# **ğŸ”¹ è·å–æœ€æ–°çš„ `96` å¤©è¾“å…¥æ•°æ®**
seq_len = 365  # å¿…é¡»å’Œè®­ç»ƒæ—¶çš„ `seq_len` ä¿æŒä¸€è‡´
latest_data = df.iloc[-seq_len:][['Open', 'Close', 'High', 'Low', 'Volume', 'DFF']].values

# **ğŸ”¹ å½’ä¸€åŒ–æ•°æ®**
scaler = StandardScaler()
# **ç¡®ä¿ fit å’Œ transform è¾“å…¥ç›¸åŒ**
scaler.fit(df[['Open', 'Close', 'High', 'Low', 'Volume', 'DFF']].values)  # è½¬æ¢ä¸º NumPy æ•°ç»„
latest_data_scaled = scaler.transform(latest_data)  # ç¡®ä¿ä¸€è‡´


# **ğŸ”¹ è½¬æ¢ä¸º Tensor**
latest_data_scaled = torch.tensor(latest_data_scaled, dtype=torch.float32).unsqueeze(0).to(device)  # (1, seq_len, 6)

# **ğŸ”¹ æœªæ¥ 7 å¤©æ—¶é—´æˆ³**
last_date = df['date'].iloc[-1]
future_dates = [last_date + timedelta(days=i + 1) for i in range(pred_len)]

# **ğŸ”¹ ç”Ÿæˆ `x_mark_enc`**
def generate_time_features(dates):
    """ ç”Ÿæˆæ—¶é—´ç‰¹å¾ï¼šæœˆã€æ—¥ã€æ˜ŸæœŸ """
    return np.array([[d.month, d.day, d.weekday()] for d in dates], dtype=np.float32)

x_mark_enc = generate_time_features(df['date'].iloc[-seq_len:])  # å–æœ€è¿‘ `seq_len` å¤©çš„æ—¶é—´ç‰¹å¾
x_mark_dec = generate_time_features(future_dates)  # æœªæ¥ `pred_len` å¤©çš„æ—¶é—´ç‰¹å¾

# **ğŸ”¹ è½¬æ¢ä¸º Tensor**
x_mark_enc = torch.tensor(x_mark_enc, dtype=torch.float32).unsqueeze(0).to(device)  # (1, seq_len, 3)
x_mark_dec = torch.tensor(x_mark_dec, dtype=torch.float32).unsqueeze(0).to(device)  # (1, pred_len, 3)

# **ğŸ”¹ æ‰‹åŠ¨æ„é€  `model_configs`ï¼Œç¡®ä¿åŒ…å«æ‰€æœ‰è¶…å‚æ•°**
from argparse import Namespace
model_configs = Namespace(
    enc_in=6, dec_in=6, c_out=6, seq_len=365, pred_len=pred_len, label_len=48,
    d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, dropout=0.1, factor=1,
    activation='gelu', output_attention=False, use_norm=True, embed='timeF',
    freq='h', class_strategy='projection'
)

# **ğŸ”¹ åˆå§‹åŒ–æ¨¡å‹**
model = Model(model_configs).to(device)

# **ğŸ”¹ åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡**
model.load_state_dict(torch.load(checkpoint_path, map_location=device))
model.eval()

# **ğŸ”¹ è¿›è¡Œé¢„æµ‹**
with torch.no_grad():
    x_dec = torch.zeros((1, pred_len, 6)).to(device)  # ç©ºçš„è§£ç å™¨è¾“å…¥
    predicted_seq = model(latest_data_scaled, x_mark_enc, x_dec, x_mark_dec)

# **ğŸ”¹ é€†å½’ä¸€åŒ–**
predictions = predicted_seq.cpu().numpy().squeeze()
predictions_original = scaler.inverse_transform(predictions)  # è¿˜åŸåˆ°çœŸå®æ•°æ®

# **ğŸ”¹ ä¿å­˜é¢„æµ‹ç»“æœ**
df_preds = pd.DataFrame(predictions_original, columns=['Open', 'Close', 'High', 'Low', 'Volume', 'DFF'])
df_preds.insert(0, 'date', future_dates)  # æ·»åŠ æ—¥æœŸåˆ—

# **ğŸ”¹ å¯¼å‡º CSV æ–‡ä»¶**
pred_csv_path = "predicted_stock_7days.csv"
df_preds.to_csv(pred_csv_path, index=False)
print(f"âœ… é¢„æµ‹å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {pred_csv_path}")

# **ğŸ”¹ æ˜¾ç¤ºé¢„æµ‹ç»“æœ**
print(df_preds)
